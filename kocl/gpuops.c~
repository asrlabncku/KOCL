/*
 * This work is licensed under the terms of the GNU GPL, version 2.  See
 * the GPL-COPYING file in the top-level directory.
 *
 * Copyright (c) 2010-2011 University of Utah and the Flux Group.
 * All rights reserved.
 *
 */


#include <stdlib.h>
#include <stdio.h>
#include "helper.h"
#include "gputils.h"

#define CL_USE_DEPRECATED_OPENCL_1_2_APIS
#include <CL/cl.h>

#define MAX_SOURCE_SIZE 1024000

 void gpu_init();
 void gpu_finit();

 void *gpu_alloc_pinned_mem(unsigned long size);
 void gpu_free_pinned_mem(void *p);

 void gpu_pin_mem(void *p, size_t sz);
 void gpu_unpin_mem(void *p);

 int gpu_alloc_device_mem(struct kgpu_service_request *sreq);
 void gpu_free_device_mem(struct kgpu_service_request *sreq);
 int gpu_alloc_cmdQueue(struct kgpu_service_request *sreq);
 void gpu_free_cmdQueue(struct kgpu_service_request *sreq);

 int gpu_execution_finished(struct kgpu_service_request *sreq);
 int gpu_post_finished(struct kgpu_service_request *sreq);

 cl_command_queue gpu_get_cmdQueue(int sid);

 int GetHw();
 int LoadKernel();

struct kgpu_gpu_mem_info devbuf;
struct kgpu_gpu_mem_info devbuf4vma;

#define MAX_QUEUE_NR 8
cl_int ret;
cl_uint numPlatforms = 0;
cl_platform_id *platforms = NULL;
cl_uint numDevices = 0;
cl_device_id *devices = NULL;

cl_context context = NULL;

cl_command_queue  cmdQueue[MAX_QUEUE_NR];
cl_command_queue  mapQueue;
static int Queueuses[MAX_QUEUE_NR];

cl_program program;
cl_kernel kernel ;

char   plat_name[10240];
char device_name[10240];

cl_mem  hostPinBuf;

char *cl_filename = "jhash_ker.cl";
char *source_str;
size_t source_size;

/*Get the OpenCL platforms and devices */
int GetHw(){
    
    

    cl_err(clGetPlatformIDs(0, NULL, &numPlatforms));
    platforms =(cl_platform_id*)malloc(numPlatforms*sizeof(cl_platform_id));

    cl_err(clGetPlatformIDs(numPlatforms, platforms , NULL));          
    cl_err(clGetPlatformInfo(platforms[1], CL_PLATFORM_NAME, 10240, plat_name, NULL));

    cl_err(clGetDeviceIDs(platforms[1],CL_DEVICE_TYPE_ALL,0,NULL, &numDevices));
    devices =(cl_device_id*)malloc(numDevices*sizeof(cl_device_id));
    cl_err(clGetDeviceIDs(platforms[1],CL_DEVICE_TYPE_ALL, numDevices , devices ,NULL));
	cl_err(clGetDeviceInfo(devices[0], CL_DEVICE_NAME, sizeof(plat_name), device_name, NULL));    
       
	printf("PROFILE = %s\n", plat_name);
    printf("DEVICE_NAME = %s\n", device_name );	
  
   return 0;
}

/*Load the Kernel*/
int LoadKernel(char *cl_filename, char **source_str, size_t *source_size)
{
    FILE *fp;
    fp = fopen(cl_filename, "r");
    if (!fp) {
        fprintf(stderr, "Failed to load kernel.\n");
        exit(1);
    }

    *source_str = (char*)malloc(MAX_SOURCE_SIZE);
    *source_size = fread(*source_str, 1, MAX_SOURCE_SIZE, fp);
    fclose(fp);
    return 0;
}

void gpu_init()
{
    LoadKernel( cl_filename, &source_str, &source_size);
    
    GetHw();   

    context = clCreateContext(NULL, numDevices ,devices , NULL, NULL, &ret);
    cl_err(ret);    
    /*Using mapQueue to map the cl_mem buffer to host */
    mapQueue = clCreateCommandQueue( context, devices[0], CL_QUEUE_PROFILING_ENABLE , &ret);
    cl_err(ret);
    program = clCreateProgramWithSource(context , 1 ,(const char**)&source_str,(const size_t *)&source_size , &ret);
    cl_err(ret);
    ret = clBuildProgram(program, numDevices, devices, NULL,  NULL,  NULL);
    cl_err(ret);
   
    int i;
    for (i=0; i<MAX_QUEUE_NR; i++) {
        cmdQueue[i]= clCreateCommandQueue( context, devices[0], CL_QUEUE_PROFILING_ENABLE , &ret);
        cl_err(ret);
	Queueuses[i] = 0;
    }  
    printf("clCreateCommandQueue ok ~\n");     
}

void gpu_finit()
{
    int i;
    clReleaseKernel(kernel);
    clReleaseProgram(program);
    for (i=0; i<MAX_QUEUE_NR; i++) {
	cl_err( clReleaseCommandQueue(cmdQueue[i]));
    }
    clReleaseContext(context);
    free(platforms);
    free(devices);
}

cl_command_queue gpu_get_cmdQueue(int stid)
{
    if (stid < 0 || stid >= MAX_QUEUE_NR)
	return 0;
    else
	return (cl_command_queue)cmdQueue[stid];
}

/*Allocate Hoast Pinned memory */
void *gpu_alloc_pinned_mem(unsigned long size) {

    void *h;   
    cl_event map_event;

    hostPinBuf = clCreateBuffer( context, CL_MEM_READ_WRITE | CL_MEM_ALLOC_HOST_PTR , size , NULL , &ret);
    cl_err(ret);
    h=clEnqueueMapBuffer( mapQueue, hostPinBuf, CL_TRUE , CL_MAP_WRITE, 0 , size , 0 , NULL, &map_event, &ret);
    cl_err(ret);
    clWaitForEvents(1, &map_event);
    return h;
}


void gpu_free_pinned_mem(void* p) {

    cl_event map_event; 
    clEnqueueUnmapMemObject(mapQueue, hostPinBuf , p , 0 , NULL , &map_event); 
    clWaitForEvents(1, &map_event);
    clReleaseMemObject(hostPinBuf);
}

static int __check_cmdQueue_done(cl_command_queue Q)
{
    cl_int e = clFinish(Q);
    if (e == CL_SUCCESS) {
	    return 1;
      } 
    else 
	  cl_err(e);
    return 0;
}

int gpu_execution_finished(struct kgpu_service_request *sreq)
{
    cl_command_queue Q = (cl_command_queue)gpu_get_cmdQueue(sreq->queue_id);
    return __check_cmdQueue_done(Q);
}

int gpu_post_finished(struct kgpu_service_request *sreq)
{
    cl_command_queue Q = (cl_command_queue)gpu_get_cmdQueue(sreq->queue_id);
    return __check_cmdQueue_done(Q);
}


/*
 * A little bit old policy, but may give you a brief pic of what
 * K-U mm does.
 *
 * Allocation policy is simple here: copy what the kernel part does
 * for the GPU memory. This works because:
 *   - GPU memory and host memory are identical in size
 *   - Whenever a host memory region is allocated, the same-sized
 *     GPU memory must be used for its GPU computation.
 *   - The data field in ku_request also uses pinned memory but we
 *     won't allocate GPU memory for it cause it is just for
 *     service provider. This is fine since the data tend to be
 *     very tiny.
 */
int gpu_alloc_device_mem(struct kgpu_service_request *sreq)
{
     cl_mem  devInBuf;
     cl_mem  devOutBuf;   
     
    sreq->devInBuf = clCreateBuffer( context , CL_MEM_READ_WRITE  , sreq->insize  , NULL , &ret);
    cl_err(ret);
    sreq->devOutBuf = clCreateBuffer( context, CL_MEM_READ_WRITE  , sreq->outsize , NULL , &ret);
    cl_err(ret);

    sreq->kernel = clCreateKernel(program, "jhash", &ret);
    cl_err(ret);
  //  printf("cl_kernel ok ~\n");
    
    cl_err(clSetKernelArg(sreq->kernel,0,sizeof(cl_mem), &sreq->devInBuf));   
    cl_err(clSetKernelArg(sreq->kernel,1,sizeof(cl_mem), &sreq->devOutBuf)); 

    return 0;
}

void gpu_free_device_mem(struct kgpu_service_request *sreq)
{
    clReleaseMemObject(sreq->devInBuf); 
    clReleaseMemObject(sreq->devOutBuf);
  //  printf("ReleaseMemObject ok ~\n");
}

int gpu_alloc_cmdQueue(struct kgpu_service_request *sreq)
{
    int i;

    for (i=0; i<MAX_QUEUE_NR; i++) {
	if (!Queueuses[i]) {
	    Queueuses[i] = 1;
	    sreq->queue_id = i;
	    sreq->queue = (cl_command_queue)(cmdQueue[i]);
	    return 0;
	   }
    }
    return 1;
}

void gpu_free_cmdQueue(struct kgpu_service_request *sreq)
{
    if (sreq->queue_id >= 0 && sreq->queue_id < MAX_QUEUE_NR) {
	Queueuses[sreq->queue_id] = 0;
    }
}


